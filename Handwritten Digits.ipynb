{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are going to build a handwritten digit recognition neural network from scratch, using just python (numpy) and maths. We will be using the downloaded version of the MNIST dataset from Kaggle, and here's how it works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the IDX file format here (for the MNIST dataset). Hence, we have to convert it to a CSV file first, which can make things easier when it comes to setting up arrays.\n",
    "\n",
    "There are 4 files under the archive zip folder after you extract it. For training, we can use `train-images.idx3-ubyte`, which are the images themselves, merging with `train-labels.idx1-ubyte`, which are the labels of the images in the dataset in order. \n",
    "(In the original downloaded dataset, the file for images and the labels are separated. Hence, we have to merge them together.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "images = read_idx('C:/Users/zoe/OneDrive/Deep Learning Projects/Handwritten Digits/archive/train-images.idx3-ubyte')\n",
    "\n",
    "images_flat = images.reshape(images.shape[0], -1)\n",
    "df1 = pd.DataFrame(images_flat)\n",
    "\n",
    "df1.to_csv('train-images.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "labels = read_idx('C:/Users/zoe/OneDrive/Deep Learning Projects/Handwritten Digits/archive/train-labels.idx1-ubyte')\n",
    "\n",
    "df2 = pd.DataFrame(labels, columns=['label'])\n",
    "\n",
    "df2.to_csv('train-labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  0  1  2  3  4  5  6  7  8  ...  774  775  776  777  778  779  780  \\\n",
       "0      5  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "1      0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2      4  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3      1  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "4      9  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "   781  782  783  \n",
       "0    0    0    0  \n",
       "1    0    0    0  \n",
       "2    0    0    0  \n",
       "3    0    0    0  \n",
       "4    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the 2 datasets\n",
    "df1 = pd.read_csv('C:/Users/zoe/OneDrive/Deep Learning Projects/Handwritten Digits/train-images.csv')\n",
    "df2 = pd.read_csv('C:/Users/zoe/OneDrive/Deep Learning Projects/Handwritten Digits/train-labels.csv')\n",
    "\n",
    "data = pd.concat([df2, df1], axis=1)\n",
    "\n",
    "data.to_csv('combined-dataset.csv', index=False)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to make this into an array. We see that there are 784 inputs for each row (excluding the label column), each representing a pixel in that 28*28 sized photo of handwritten digit. \n",
    "\n",
    "We will try to shuffle these arrays for making the whole datastructure more \"random\" for the training (you can think of it as less easy for the neural network to recognise those patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 0, ..., 0, 0, 0],\n",
       "       [6, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [3, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], shape=(60000, 785))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = np.array(data)\n",
    "np.random.shuffle(nodes)\n",
    "\n",
    "nodes.shape\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a bunch of arrays that represents the **input layer**. Using `nodes.shape` we can check the dimensions of these arrays again (60000 is the number of rows, 785 is the number of columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: we need to split nodes dataset into 3 types of datasets: 1. training dataset; 2. validation dataset; 3. testing dataset. For validation dataset, it is to check that the neural network didn't memorise the training data and it has really done some learning from it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by picking out 2000 validation dataset. For the equation in neural networks (more explanation in medium blog post/ readme file), it should be something like y = activation function on the summation of (weight matrix * nodes + bias). \n",
    "\n",
    "A very important remark is that if we don't transpose the node sample (reason would be explained in blog/ readme file as well), we would not get the Y_valid and X_valid we wanted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 1 ... 0 2 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "2000\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "nodes_valid = nodes[:2000].T\n",
    "\n",
    "# Transpose th= nodes_validle as it is originally a row vector -> we want it to be a column vecto= nodes_valid = nodes_valid.T\n",
    "\n",
    "Y_valid = nodes_valid[0]\n",
    "X_valid = nodes_valid[1:]\n",
    "\n",
    "# Check the contents in X_valid and Y_valid\n",
    "print(Y_valid)\n",
    "print(X_valid)\n",
    "\n",
    "# Check the size of X_valid and Y_valid\n",
    "# For X_valid, we just need the first row vector to check the size\n",
    "print(Y_valid.size)\n",
    "print(X_valid[:,0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Y_valid are the final results we get from the **output layer**, and X_valid is somethng we called an **activation**, which is a value in those input layer nodes that we have inputed in it. \n",
    "\n",
    "Now, we prepare the training dataset. As the testing dataset is included in another file under the archive foler: `t10k-images.idx3-ubyte` and `t10k-labels.idx1-ubyte`, so we just set the remaining datasets here to be the training dataset. For the ratio between the number (size) of these datasets, it's better to follow 2:6:2 (valid: train: test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 1 ... 7 5 6]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "6000\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "nodes_train = nodes[2001: 8001].T\n",
    "\n",
    "Y_train = nodes_train[0]\n",
    "X_train = nodes_train[1:]\n",
    "\n",
    "print(Y_train)\n",
    "print(X_train)\n",
    "\n",
    "print(Y_train.size)\n",
    "print(X_train[:,0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters():\n",
    "    W1 = np.random.rand(10, 784) - 0.5 \n",
    "    b1 = np.random.rand(10, 1) - 0.5 \n",
    "    W2 = np.random.rand(10, 784) - 0.5 \n",
    "    b2 = np.random.rand(10, 1) - 0.5 \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))  # Subtract max(z) for numerical stability\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    # Doing matrix operations using dot product\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    m = Y.size\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = 1/m * dZ2.dot(A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "    dW1 = 1/m * dZ1.dot(X.T)\n",
    "    db1 = 1/m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def gradient_descent (X, Y, iterations, alpha): \n",
    "    W1, b1, W2, b2 = init_parameters()\n",
    "    for i in range(iterations): \n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 50 == 0:\n",
    "            print('Iteration:', i)\n",
    "            print(\"Accuracy:\", np.mean(np.argmax(A2, axis=0) == Y))\n",
    "    return W1, b1, W2, b2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
